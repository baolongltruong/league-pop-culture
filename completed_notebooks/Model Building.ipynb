{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ec64bee",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ba63664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.sql import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ec8b972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "699b6d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, classification_report, accuracy_score, confusion_matrix \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ebcf19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2\n",
      "  Downloading psycopg2-2.9.3-cp39-cp39-win_amd64.whl (1.2 MB)\n",
      "Installing collected packages: psycopg2\n",
      "Successfully installed psycopg2-2.9.3\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c57e6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('XXXXXXX://XXXXXXX:XXXXXXX:XXXXXXX/XXXXXXX')\n",
    "conn = engine.connect().execution_options(autocommit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b425381",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sig = pd.read_sql_query('select * from significance_table as st join submission_vectors as sv on st.submission_id = sv.submission_id where t_sample_t_test is not null;', con = conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94cc181f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>upvotes</th>\n",
       "      <th>t_sample_t_test</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.804775</td>\n",
       "      <td>0.315904</td>\n",
       "      <td>-0.045163</td>\n",
       "      <td>0.100483</td>\n",
       "      <td>0.480817</td>\n",
       "      <td>0.443167</td>\n",
       "      <td>-0.319338</td>\n",
       "      <td>0.516226</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095464</td>\n",
       "      <td>0.503082</td>\n",
       "      <td>0.525933</td>\n",
       "      <td>-0.406394</td>\n",
       "      <td>0.815783</td>\n",
       "      <td>0.151320</td>\n",
       "      <td>-0.144457</td>\n",
       "      <td>-0.481676</td>\n",
       "      <td>-0.180171</td>\n",
       "      <td>-0.400925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1040</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.185703</td>\n",
       "      <td>0.023682</td>\n",
       "      <td>0.207782</td>\n",
       "      <td>0.530416</td>\n",
       "      <td>-0.544296</td>\n",
       "      <td>0.114059</td>\n",
       "      <td>-0.380009</td>\n",
       "      <td>0.627888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041726</td>\n",
       "      <td>0.392014</td>\n",
       "      <td>0.440717</td>\n",
       "      <td>0.400752</td>\n",
       "      <td>0.027663</td>\n",
       "      <td>0.116840</td>\n",
       "      <td>-0.704573</td>\n",
       "      <td>0.659166</td>\n",
       "      <td>0.310418</td>\n",
       "      <td>-0.337699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.516388</td>\n",
       "      <td>0.254332</td>\n",
       "      <td>0.183559</td>\n",
       "      <td>0.475579</td>\n",
       "      <td>0.455851</td>\n",
       "      <td>0.557130</td>\n",
       "      <td>-0.195927</td>\n",
       "      <td>0.583042</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130465</td>\n",
       "      <td>0.116177</td>\n",
       "      <td>0.354175</td>\n",
       "      <td>0.015838</td>\n",
       "      <td>-0.305019</td>\n",
       "      <td>-0.006427</td>\n",
       "      <td>-0.540465</td>\n",
       "      <td>-0.014772</td>\n",
       "      <td>0.244741</td>\n",
       "      <td>-0.074475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.192984</td>\n",
       "      <td>-0.142646</td>\n",
       "      <td>0.125904</td>\n",
       "      <td>0.382128</td>\n",
       "      <td>0.254417</td>\n",
       "      <td>0.257000</td>\n",
       "      <td>-0.637827</td>\n",
       "      <td>0.068707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124186</td>\n",
       "      <td>0.797552</td>\n",
       "      <td>0.310523</td>\n",
       "      <td>-0.135499</td>\n",
       "      <td>0.940158</td>\n",
       "      <td>0.501260</td>\n",
       "      <td>-0.530605</td>\n",
       "      <td>-0.101638</td>\n",
       "      <td>0.484378</td>\n",
       "      <td>-1.014775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.192984</td>\n",
       "      <td>-0.142646</td>\n",
       "      <td>0.125904</td>\n",
       "      <td>0.382128</td>\n",
       "      <td>0.254417</td>\n",
       "      <td>0.257000</td>\n",
       "      <td>-0.637827</td>\n",
       "      <td>0.068707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124186</td>\n",
       "      <td>0.797552</td>\n",
       "      <td>0.310523</td>\n",
       "      <td>-0.135499</td>\n",
       "      <td>0.940158</td>\n",
       "      <td>0.501260</td>\n",
       "      <td>-0.530605</td>\n",
       "      <td>-0.101638</td>\n",
       "      <td>0.484378</td>\n",
       "      <td>-1.014775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32734</th>\n",
       "      <td>174</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.286790</td>\n",
       "      <td>-0.243372</td>\n",
       "      <td>0.259694</td>\n",
       "      <td>0.596197</td>\n",
       "      <td>-0.380780</td>\n",
       "      <td>-0.032148</td>\n",
       "      <td>0.061175</td>\n",
       "      <td>0.234752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.400553</td>\n",
       "      <td>0.664949</td>\n",
       "      <td>0.484354</td>\n",
       "      <td>0.101292</td>\n",
       "      <td>0.173315</td>\n",
       "      <td>0.235715</td>\n",
       "      <td>-0.620059</td>\n",
       "      <td>-0.012455</td>\n",
       "      <td>0.445785</td>\n",
       "      <td>-0.026895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32735</th>\n",
       "      <td>174</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.286790</td>\n",
       "      <td>-0.243372</td>\n",
       "      <td>0.259694</td>\n",
       "      <td>0.596197</td>\n",
       "      <td>-0.380780</td>\n",
       "      <td>-0.032148</td>\n",
       "      <td>0.061175</td>\n",
       "      <td>0.234752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.400553</td>\n",
       "      <td>0.664949</td>\n",
       "      <td>0.484354</td>\n",
       "      <td>0.101292</td>\n",
       "      <td>0.173315</td>\n",
       "      <td>0.235715</td>\n",
       "      <td>-0.620059</td>\n",
       "      <td>-0.012455</td>\n",
       "      <td>0.445785</td>\n",
       "      <td>-0.026895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32736</th>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.221735</td>\n",
       "      <td>-0.005563</td>\n",
       "      <td>0.136709</td>\n",
       "      <td>0.446870</td>\n",
       "      <td>-0.313393</td>\n",
       "      <td>0.185552</td>\n",
       "      <td>-0.421806</td>\n",
       "      <td>0.473120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197290</td>\n",
       "      <td>0.318249</td>\n",
       "      <td>0.350785</td>\n",
       "      <td>0.158812</td>\n",
       "      <td>0.144754</td>\n",
       "      <td>0.085425</td>\n",
       "      <td>-0.757788</td>\n",
       "      <td>0.405676</td>\n",
       "      <td>0.390924</td>\n",
       "      <td>-0.353025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32737</th>\n",
       "      <td>1575</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.356414</td>\n",
       "      <td>0.122949</td>\n",
       "      <td>0.040761</td>\n",
       "      <td>0.409273</td>\n",
       "      <td>-0.053394</td>\n",
       "      <td>0.316902</td>\n",
       "      <td>0.157393</td>\n",
       "      <td>0.449702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306242</td>\n",
       "      <td>-0.034132</td>\n",
       "      <td>0.334505</td>\n",
       "      <td>0.188771</td>\n",
       "      <td>0.046193</td>\n",
       "      <td>-0.066672</td>\n",
       "      <td>-0.695834</td>\n",
       "      <td>0.058594</td>\n",
       "      <td>0.004527</td>\n",
       "      <td>-0.310824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32738</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.876947</td>\n",
       "      <td>0.388674</td>\n",
       "      <td>0.577009</td>\n",
       "      <td>-0.533535</td>\n",
       "      <td>-0.360431</td>\n",
       "      <td>0.439926</td>\n",
       "      <td>-0.068141</td>\n",
       "      <td>-0.190432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497551</td>\n",
       "      <td>1.106310</td>\n",
       "      <td>-0.610491</td>\n",
       "      <td>0.593853</td>\n",
       "      <td>1.490107</td>\n",
       "      <td>-0.162837</td>\n",
       "      <td>-1.350688</td>\n",
       "      <td>0.967860</td>\n",
       "      <td>-0.104110</td>\n",
       "      <td>-0.494431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32739 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       upvotes  t_sample_t_test         0         1         2         3  \\\n",
       "0            3            False -0.804775  0.315904 -0.045163  0.100483   \n",
       "1         1040            False -0.185703  0.023682  0.207782  0.530416   \n",
       "2            0            False -0.516388  0.254332  0.183559  0.475579   \n",
       "3            0            False -0.192984 -0.142646  0.125904  0.382128   \n",
       "4            0            False -0.192984 -0.142646  0.125904  0.382128   \n",
       "...        ...              ...       ...       ...       ...       ...   \n",
       "32734      174            False -0.286790 -0.243372  0.259694  0.596197   \n",
       "32735      174            False -0.286790 -0.243372  0.259694  0.596197   \n",
       "32736       20            False -0.221735 -0.005563  0.136709  0.446870   \n",
       "32737     1575            False -0.356414  0.122949  0.040761  0.409273   \n",
       "32738        0            False -0.876947  0.388674  0.577009 -0.533535   \n",
       "\n",
       "              4         5         6         7  ...        90        91  \\\n",
       "0      0.480817  0.443167 -0.319338  0.516226  ... -0.095464  0.503082   \n",
       "1     -0.544296  0.114059 -0.380009  0.627888  ...  0.041726  0.392014   \n",
       "2      0.455851  0.557130 -0.195927  0.583042  ... -0.130465  0.116177   \n",
       "3      0.254417  0.257000 -0.637827  0.068707  ...  0.124186  0.797552   \n",
       "4      0.254417  0.257000 -0.637827  0.068707  ...  0.124186  0.797552   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "32734 -0.380780 -0.032148  0.061175  0.234752  ... -0.400553  0.664949   \n",
       "32735 -0.380780 -0.032148  0.061175  0.234752  ... -0.400553  0.664949   \n",
       "32736 -0.313393  0.185552 -0.421806  0.473120  ...  0.197290  0.318249   \n",
       "32737 -0.053394  0.316902  0.157393  0.449702  ...  0.306242 -0.034132   \n",
       "32738 -0.360431  0.439926 -0.068141 -0.190432  ...  0.497551  1.106310   \n",
       "\n",
       "             92        93        94        95        96        97        98  \\\n",
       "0      0.525933 -0.406394  0.815783  0.151320 -0.144457 -0.481676 -0.180171   \n",
       "1      0.440717  0.400752  0.027663  0.116840 -0.704573  0.659166  0.310418   \n",
       "2      0.354175  0.015838 -0.305019 -0.006427 -0.540465 -0.014772  0.244741   \n",
       "3      0.310523 -0.135499  0.940158  0.501260 -0.530605 -0.101638  0.484378   \n",
       "4      0.310523 -0.135499  0.940158  0.501260 -0.530605 -0.101638  0.484378   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "32734  0.484354  0.101292  0.173315  0.235715 -0.620059 -0.012455  0.445785   \n",
       "32735  0.484354  0.101292  0.173315  0.235715 -0.620059 -0.012455  0.445785   \n",
       "32736  0.350785  0.158812  0.144754  0.085425 -0.757788  0.405676  0.390924   \n",
       "32737  0.334505  0.188771  0.046193 -0.066672 -0.695834  0.058594  0.004527   \n",
       "32738 -0.610491  0.593853  1.490107 -0.162837 -1.350688  0.967860 -0.104110   \n",
       "\n",
       "             99  \n",
       "0     -0.400925  \n",
       "1     -0.337699  \n",
       "2     -0.074475  \n",
       "3     -1.014775  \n",
       "4     -1.014775  \n",
       "...         ...  \n",
       "32734 -0.026895  \n",
       "32735 -0.026895  \n",
       "32736 -0.353025  \n",
       "32737 -0.310824  \n",
       "32738 -0.494431  \n",
       "\n",
       "[32739 rows x 102 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs = df_sig.drop(columns=['submission_id','topic_champion','date'])\n",
    "df_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da18fb83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = df_inputs.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "478dd576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89dd9f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = cols[0:1] + cols[2:102] + cols[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a990daab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8714e019",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['upvotes',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '34',\n",
       " '35',\n",
       " '36',\n",
       " '37',\n",
       " '38',\n",
       " '39',\n",
       " '40',\n",
       " '41',\n",
       " '42',\n",
       " '43',\n",
       " '44',\n",
       " '45',\n",
       " '46',\n",
       " '47',\n",
       " '48',\n",
       " '49',\n",
       " '50',\n",
       " '51',\n",
       " '52',\n",
       " '53',\n",
       " '54',\n",
       " '55',\n",
       " '56',\n",
       " '57',\n",
       " '58',\n",
       " '59',\n",
       " '60',\n",
       " '61',\n",
       " '62',\n",
       " '63',\n",
       " '64',\n",
       " '65',\n",
       " '66',\n",
       " '67',\n",
       " '68',\n",
       " '69',\n",
       " '70',\n",
       " '71',\n",
       " '72',\n",
       " '73',\n",
       " '74',\n",
       " '75',\n",
       " '76',\n",
       " '77',\n",
       " '78',\n",
       " '79',\n",
       " '80',\n",
       " '81',\n",
       " '82',\n",
       " '83',\n",
       " '84',\n",
       " '85',\n",
       " '86',\n",
       " '87',\n",
       " '88',\n",
       " '89',\n",
       " '90',\n",
       " '91',\n",
       " '92',\n",
       " '93',\n",
       " '94',\n",
       " '95',\n",
       " '96',\n",
       " '97',\n",
       " '98',\n",
       " '99',\n",
       " 't_sample_t_test']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "358dbeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs = df_inputs[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddf200cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>upvotes</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>t_sample_t_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.804775</td>\n",
       "      <td>0.315904</td>\n",
       "      <td>-0.045163</td>\n",
       "      <td>0.100483</td>\n",
       "      <td>0.480817</td>\n",
       "      <td>0.443167</td>\n",
       "      <td>-0.319338</td>\n",
       "      <td>0.516226</td>\n",
       "      <td>0.806492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.503082</td>\n",
       "      <td>0.525933</td>\n",
       "      <td>-0.406394</td>\n",
       "      <td>0.815783</td>\n",
       "      <td>0.151320</td>\n",
       "      <td>-0.144457</td>\n",
       "      <td>-0.481676</td>\n",
       "      <td>-0.180171</td>\n",
       "      <td>-0.400925</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1040</td>\n",
       "      <td>-0.185703</td>\n",
       "      <td>0.023682</td>\n",
       "      <td>0.207782</td>\n",
       "      <td>0.530416</td>\n",
       "      <td>-0.544296</td>\n",
       "      <td>0.114059</td>\n",
       "      <td>-0.380009</td>\n",
       "      <td>0.627888</td>\n",
       "      <td>-0.179360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392014</td>\n",
       "      <td>0.440717</td>\n",
       "      <td>0.400752</td>\n",
       "      <td>0.027663</td>\n",
       "      <td>0.116840</td>\n",
       "      <td>-0.704573</td>\n",
       "      <td>0.659166</td>\n",
       "      <td>0.310418</td>\n",
       "      <td>-0.337699</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.516388</td>\n",
       "      <td>0.254332</td>\n",
       "      <td>0.183559</td>\n",
       "      <td>0.475579</td>\n",
       "      <td>0.455851</td>\n",
       "      <td>0.557130</td>\n",
       "      <td>-0.195927</td>\n",
       "      <td>0.583042</td>\n",
       "      <td>0.112773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116177</td>\n",
       "      <td>0.354175</td>\n",
       "      <td>0.015838</td>\n",
       "      <td>-0.305019</td>\n",
       "      <td>-0.006427</td>\n",
       "      <td>-0.540465</td>\n",
       "      <td>-0.014772</td>\n",
       "      <td>0.244741</td>\n",
       "      <td>-0.074475</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.192984</td>\n",
       "      <td>-0.142646</td>\n",
       "      <td>0.125904</td>\n",
       "      <td>0.382128</td>\n",
       "      <td>0.254417</td>\n",
       "      <td>0.257000</td>\n",
       "      <td>-0.637827</td>\n",
       "      <td>0.068707</td>\n",
       "      <td>0.139172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797552</td>\n",
       "      <td>0.310523</td>\n",
       "      <td>-0.135499</td>\n",
       "      <td>0.940158</td>\n",
       "      <td>0.501260</td>\n",
       "      <td>-0.530605</td>\n",
       "      <td>-0.101638</td>\n",
       "      <td>0.484378</td>\n",
       "      <td>-1.014775</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.192984</td>\n",
       "      <td>-0.142646</td>\n",
       "      <td>0.125904</td>\n",
       "      <td>0.382128</td>\n",
       "      <td>0.254417</td>\n",
       "      <td>0.257000</td>\n",
       "      <td>-0.637827</td>\n",
       "      <td>0.068707</td>\n",
       "      <td>0.139172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797552</td>\n",
       "      <td>0.310523</td>\n",
       "      <td>-0.135499</td>\n",
       "      <td>0.940158</td>\n",
       "      <td>0.501260</td>\n",
       "      <td>-0.530605</td>\n",
       "      <td>-0.101638</td>\n",
       "      <td>0.484378</td>\n",
       "      <td>-1.014775</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32734</th>\n",
       "      <td>174</td>\n",
       "      <td>-0.286790</td>\n",
       "      <td>-0.243372</td>\n",
       "      <td>0.259694</td>\n",
       "      <td>0.596197</td>\n",
       "      <td>-0.380780</td>\n",
       "      <td>-0.032148</td>\n",
       "      <td>0.061175</td>\n",
       "      <td>0.234752</td>\n",
       "      <td>0.055850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664949</td>\n",
       "      <td>0.484354</td>\n",
       "      <td>0.101292</td>\n",
       "      <td>0.173315</td>\n",
       "      <td>0.235715</td>\n",
       "      <td>-0.620059</td>\n",
       "      <td>-0.012455</td>\n",
       "      <td>0.445785</td>\n",
       "      <td>-0.026895</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32735</th>\n",
       "      <td>174</td>\n",
       "      <td>-0.286790</td>\n",
       "      <td>-0.243372</td>\n",
       "      <td>0.259694</td>\n",
       "      <td>0.596197</td>\n",
       "      <td>-0.380780</td>\n",
       "      <td>-0.032148</td>\n",
       "      <td>0.061175</td>\n",
       "      <td>0.234752</td>\n",
       "      <td>0.055850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664949</td>\n",
       "      <td>0.484354</td>\n",
       "      <td>0.101292</td>\n",
       "      <td>0.173315</td>\n",
       "      <td>0.235715</td>\n",
       "      <td>-0.620059</td>\n",
       "      <td>-0.012455</td>\n",
       "      <td>0.445785</td>\n",
       "      <td>-0.026895</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32736</th>\n",
       "      <td>20</td>\n",
       "      <td>-0.221735</td>\n",
       "      <td>-0.005563</td>\n",
       "      <td>0.136709</td>\n",
       "      <td>0.446870</td>\n",
       "      <td>-0.313393</td>\n",
       "      <td>0.185552</td>\n",
       "      <td>-0.421806</td>\n",
       "      <td>0.473120</td>\n",
       "      <td>-0.163098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318249</td>\n",
       "      <td>0.350785</td>\n",
       "      <td>0.158812</td>\n",
       "      <td>0.144754</td>\n",
       "      <td>0.085425</td>\n",
       "      <td>-0.757788</td>\n",
       "      <td>0.405676</td>\n",
       "      <td>0.390924</td>\n",
       "      <td>-0.353025</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32737</th>\n",
       "      <td>1575</td>\n",
       "      <td>-0.356414</td>\n",
       "      <td>0.122949</td>\n",
       "      <td>0.040761</td>\n",
       "      <td>0.409273</td>\n",
       "      <td>-0.053394</td>\n",
       "      <td>0.316902</td>\n",
       "      <td>0.157393</td>\n",
       "      <td>0.449702</td>\n",
       "      <td>0.471984</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034132</td>\n",
       "      <td>0.334505</td>\n",
       "      <td>0.188771</td>\n",
       "      <td>0.046193</td>\n",
       "      <td>-0.066672</td>\n",
       "      <td>-0.695834</td>\n",
       "      <td>0.058594</td>\n",
       "      <td>0.004527</td>\n",
       "      <td>-0.310824</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32738</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.876947</td>\n",
       "      <td>0.388674</td>\n",
       "      <td>0.577009</td>\n",
       "      <td>-0.533535</td>\n",
       "      <td>-0.360431</td>\n",
       "      <td>0.439926</td>\n",
       "      <td>-0.068141</td>\n",
       "      <td>-0.190432</td>\n",
       "      <td>-0.403182</td>\n",
       "      <td>...</td>\n",
       "      <td>1.106310</td>\n",
       "      <td>-0.610491</td>\n",
       "      <td>0.593853</td>\n",
       "      <td>1.490107</td>\n",
       "      <td>-0.162837</td>\n",
       "      <td>-1.350688</td>\n",
       "      <td>0.967860</td>\n",
       "      <td>-0.104110</td>\n",
       "      <td>-0.494431</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32739 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       upvotes         0         1         2         3         4         5  \\\n",
       "0            3 -0.804775  0.315904 -0.045163  0.100483  0.480817  0.443167   \n",
       "1         1040 -0.185703  0.023682  0.207782  0.530416 -0.544296  0.114059   \n",
       "2            0 -0.516388  0.254332  0.183559  0.475579  0.455851  0.557130   \n",
       "3            0 -0.192984 -0.142646  0.125904  0.382128  0.254417  0.257000   \n",
       "4            0 -0.192984 -0.142646  0.125904  0.382128  0.254417  0.257000   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "32734      174 -0.286790 -0.243372  0.259694  0.596197 -0.380780 -0.032148   \n",
       "32735      174 -0.286790 -0.243372  0.259694  0.596197 -0.380780 -0.032148   \n",
       "32736       20 -0.221735 -0.005563  0.136709  0.446870 -0.313393  0.185552   \n",
       "32737     1575 -0.356414  0.122949  0.040761  0.409273 -0.053394  0.316902   \n",
       "32738        0 -0.876947  0.388674  0.577009 -0.533535 -0.360431  0.439926   \n",
       "\n",
       "              6         7         8  ...        91        92        93  \\\n",
       "0     -0.319338  0.516226  0.806492  ...  0.503082  0.525933 -0.406394   \n",
       "1     -0.380009  0.627888 -0.179360  ...  0.392014  0.440717  0.400752   \n",
       "2     -0.195927  0.583042  0.112773  ...  0.116177  0.354175  0.015838   \n",
       "3     -0.637827  0.068707  0.139172  ...  0.797552  0.310523 -0.135499   \n",
       "4     -0.637827  0.068707  0.139172  ...  0.797552  0.310523 -0.135499   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "32734  0.061175  0.234752  0.055850  ...  0.664949  0.484354  0.101292   \n",
       "32735  0.061175  0.234752  0.055850  ...  0.664949  0.484354  0.101292   \n",
       "32736 -0.421806  0.473120 -0.163098  ...  0.318249  0.350785  0.158812   \n",
       "32737  0.157393  0.449702  0.471984  ... -0.034132  0.334505  0.188771   \n",
       "32738 -0.068141 -0.190432 -0.403182  ...  1.106310 -0.610491  0.593853   \n",
       "\n",
       "             94        95        96        97        98        99  \\\n",
       "0      0.815783  0.151320 -0.144457 -0.481676 -0.180171 -0.400925   \n",
       "1      0.027663  0.116840 -0.704573  0.659166  0.310418 -0.337699   \n",
       "2     -0.305019 -0.006427 -0.540465 -0.014772  0.244741 -0.074475   \n",
       "3      0.940158  0.501260 -0.530605 -0.101638  0.484378 -1.014775   \n",
       "4      0.940158  0.501260 -0.530605 -0.101638  0.484378 -1.014775   \n",
       "...         ...       ...       ...       ...       ...       ...   \n",
       "32734  0.173315  0.235715 -0.620059 -0.012455  0.445785 -0.026895   \n",
       "32735  0.173315  0.235715 -0.620059 -0.012455  0.445785 -0.026895   \n",
       "32736  0.144754  0.085425 -0.757788  0.405676  0.390924 -0.353025   \n",
       "32737  0.046193 -0.066672 -0.695834  0.058594  0.004527 -0.310824   \n",
       "32738  1.490107 -0.162837 -1.350688  0.967860 -0.104110 -0.494431   \n",
       "\n",
       "       t_sample_t_test  \n",
       "0                False  \n",
       "1                False  \n",
       "2                False  \n",
       "3                False  \n",
       "4                False  \n",
       "...                ...  \n",
       "32734            False  \n",
       "32735            False  \n",
       "32736            False  \n",
       "32737            False  \n",
       "32738            False  \n",
       "\n",
       "[32739 rows x 102 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18068e15",
   "metadata": {},
   "source": [
    "# Logistic Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "062207d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_inputs.drop(columns=['t_sample_t_test']) \n",
    "y = df_inputs.t_sample_t_test\n",
    "\n",
    "np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc49d56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "lr = LogisticRegression()\n",
    "model1 = Pipeline([('standardize', scaler),\n",
    "                    ('log_reg', lr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27cc92d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardize', StandardScaler()),\n",
       "                ('log_reg', LogisticRegression())])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "545b1de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[22589     7]\n",
      " [ 1955     3]]\n",
      "Training AUC: 61.4989 %\n",
      "Training accuracy: 92.0094 %\n"
     ]
    }
   ],
   "source": [
    "y_train_hat = model1.predict(X_train)\n",
    "y_train_hat_probs = model1.predict_proba(X_train)[:,1]\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)*100\n",
    "train_auc_roc = roc_auc_score(y_train, y_train_hat_probs)*100\n",
    "\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_train, y_train_hat))\n",
    "\n",
    "print('Training AUC: %.4f %%' % train_auc_roc)\n",
    "\n",
    "print('Training accuracy: %.4f %%' % train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92ef885e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[7533    2]\n",
      " [ 649    1]]\n",
      "Testing AUC: 55.4365 %\n",
      "Testing accuracy: 92.0464 %\n"
     ]
    }
   ],
   "source": [
    "y_test_hat = model1.predict(X_test)\n",
    "y_test_hat_probs = model1.predict_proba(X_test)[:,1]\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_hat)*100\n",
    "test_auc_roc = roc_auc_score(y_test, y_test_hat_probs)*100\n",
    "\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, y_test_hat))\n",
    "\n",
    "print('Testing AUC: %.4f %%' % test_auc_roc)\n",
    "\n",
    "print('Testing accuracy: %.4f %%' % test_accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d51a4c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False   0.920680  0.999735  0.958580      7535\n",
      "        True   0.333333  0.001538  0.003063       650\n",
      "\n",
      "    accuracy                       0.920464      8185\n",
      "   macro avg   0.627006  0.500637  0.480821      8185\n",
      "weighted avg   0.874036  0.920464  0.882699      8185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_test_hat, digits=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08e8181a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.countplot(x=\"t_sample_t_test\", data=df_inputs, palette=\"Set3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87503eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8182"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_test_hat== False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36a24b8",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac6a2136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2e221a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_inputs.drop(columns=['t_sample_t_test']) \n",
    "y = df_inputs.t_sample_t_test\n",
    "\n",
    "np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e670cc",
   "metadata": {},
   "source": [
    "## Starting Point (One Set of Hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99381c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ACCURACY OF THE MODEL:  0.9071472205253512\n"
     ]
    }
   ],
   "source": [
    "# creating a RF classifier\n",
    "clf = RandomForestClassifier(n_estimators = 100) \n",
    "\n",
    "# Training the model on the training dataset\n",
    "# fit function is used to train the model using the training sets as parameters\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# performing predictions on the test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# metrics are used to find accuracy or error\n",
    "from sklearn import metrics \n",
    "print()\n",
    "\n",
    "# using metrics module for accuracy calculation\n",
    "print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1a15b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[7399  136]\n",
      " [ 626   24]]\n"
     ]
    }
   ],
   "source": [
    "print('Confusion matrix:\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a123954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[7399  136]\n",
      " [ 626   24]]\n",
      "Testing AUC: 53.9190 %\n",
      "Testing accuracy: 90.6903 %\n"
     ]
    }
   ],
   "source": [
    "y_pred_probs = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_pred)*100\n",
    "test_auc_roc = roc_auc_score(y_test, y_pred_probs)*100\n",
    "\n",
    "\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print('Testing AUC: %.4f %%' % test_auc_roc)\n",
    "\n",
    "print('Testing accuracy: %.4f %%' % test_accuracy) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17ea73c",
   "metadata": {},
   "source": [
    "The confusion matrix appears to be better, but the testing AUC and testing accuracy are acutally **worse**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077ee7d1",
   "metadata": {},
   "source": [
    "## Multiple Permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2681e765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [100, 200, 300], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 43, 76, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False], 'class_weight': [{0: 1, 1: 12}]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 300, num = 3)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 4)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap,\n",
    "               'class_weight': [{0:1, 1:12}]}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0540dd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'class_weight': [{0: 1, 1: 12}],\n",
       "                                        'max_depth': [10, 43, 76, 110, None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 200, 300]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "be2ba717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 76,\n",
       " 'class_weight': {0: 1, 1: 12},\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4947921a",
   "metadata": {},
   "source": [
    "## \"Best\" Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d3684c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ACCURACY OF THE MODEL:  0.8984728161270616\n"
     ]
    }
   ],
   "source": [
    "# creating a RF classifier\n",
    "clf = RandomForestClassifier(n_estimators = 100,\n",
    "                            min_samples_split=10,\n",
    "                            min_samples_leaf=4,\n",
    "                            max_features='auto',\n",
    "                            max_depth=76,\n",
    "                            bootstrap=True,\n",
    "                            class_weight={0:1, 1:12}) \n",
    " \n",
    "# Training the model on the training dataset\n",
    "# fit function is used to train the model using the training sets as parameters\n",
    "clf.fit(X_train, y_train)\n",
    " \n",
    "# performing predictions on the test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    " \n",
    "# metrics are used to find accuracy or error\n",
    "from sklearn import metrics \n",
    "print()\n",
    " \n",
    "# using metrics module for accuracy calculation\n",
    "print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "320ffbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[7316  219]\n",
      " [ 612   38]]\n",
      "Testing AUC: 54.7914 %\n",
      "Testing accuracy: 89.8473 %\n"
     ]
    }
   ],
   "source": [
    "y_pred_probs = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_pred)*100\n",
    "test_auc_roc = roc_auc_score(y_test, y_pred_probs)*100\n",
    "\n",
    "\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print('Testing AUC: %.4f %%' % test_auc_roc)\n",
    "\n",
    "print('Testing accuracy: %.4f %%' % test_accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddcf9c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aKost\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x140c75e8b20>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics.plot_roc_curve(clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f551028",
   "metadata": {},
   "source": [
    "# Neural Network Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be255b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTS\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c30883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "in_f = 101\n",
    "out_f = 1\n",
    "hidden_l = [0,1,2,3,4,5]\n",
    "lr = 1e-3\n",
    "\n",
    "## CLASS\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, in_features=101, n_hidden_layers=1, out_features=1):\n",
    "\n",
    "        ## VALUE CHECKING\n",
    "        if not isinstance(in_features, int):\n",
    "            raise TypeError(f\"Instance 'in_features' must be of type 'int', received type '{type(in_features)}'\")\n",
    "        if in_features <= 1:\n",
    "            raise ValueError(f\"Attribute 'in_features' must be >= 1, received value {in_features}\")\n",
    "\n",
    "        if not isinstance(n_hidden_layers, int):\n",
    "            raise TypeError(f\"Instance 'n_hidden_layers' must be of type 'int', received type '{type(n_hidden_layers)}'\")\n",
    "        if n_hidden_layers < 0 or n_hidden_layers > 5:\n",
    "            raise ValueError(f\"Attribute 'n_hidden_layers' must be >= 0 or <= 5, received value {n_hidden_layers}\")\n",
    "\n",
    "        if not isinstance(out_features, int):\n",
    "            raise TypeError(f\"Instance 'out_features' must be of type 'int', received type '{type(out_features)}'\")\n",
    "        if out_features < 1:\n",
    "            raise ValueError(f\"Attribute 'out_features' must be >= 1 , received value {out_features}\")\n",
    "\n",
    "        super(FFN, self).__init__()\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.out_features = out_features\n",
    "\n",
    "        self.0l = nn.Sequential(\n",
    "            F.sigmoid()\n",
    "        )\n",
    "        self.1l = nn.Sequential(\n",
    "            nn.Linear(in_features, out_features),\n",
    "            nn.Dropout(0.1), \n",
    "            F.sigmoid()\n",
    "        )    \n",
    "        self.2l = nn.Sequential(\n",
    "            nn.Linear(in_features, 200),\n",
    "            nn.Dropout(0.1), \n",
    "            nn.Linear(200, out_features), \n",
    "            F.sigmoid()\n",
    "        )\n",
    "        self.3l = nn.Sequential(\n",
    "            nn.Linear(in_features, 200),\n",
    "            nn.Linear(200, 100),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(100, out_features), \n",
    "            F.sigmoid()\n",
    "        )\n",
    "        self.4l = nn.Sequential(\n",
    "            nn.Linear(in_features, 200), \n",
    "            nn.Linear(200, 200), nn.Linear(200, 100),\n",
    "            nn.Dropout(0.3), \n",
    "            nn.Linear(100, out_features),\n",
    "            F.sigmoid()\n",
    "        )\n",
    "        self.5l = nn.Sequential(\n",
    "            nn.Linear(in_features, 200), \n",
    "            nn.Linear(200, 400), nn.Linear(400, 200), nn.Linear(200, 100),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(100, out_features),\n",
    "            F.sigmoid()\n",
    "        )\n",
    "\n",
    "def forward(self, x):\n",
    "    if self.n_hidden_layers == 0:\n",
    "        return self.0l(x)\n",
    "    if self.n_hidden_layers == 1:\n",
    "        return self.1l(x)\n",
    "    elif self.n_hidden_layers == 2:\n",
    "        return self.2l(x)\n",
    "    elif self.n_hidden_layers == 3:\n",
    "        return self.3l(x)\n",
    "    elif self.n_hidden_layers == 4:\n",
    "        return self.4l(x)\n",
    "    elif self.n_hidden_layers == 5:\n",
    "        return self.5l(x)\n",
    "\n",
    "    return temp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70760f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL DEFINITION\n",
    "model = FFN(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr) \n",
    "\n",
    "## TRAINING\n",
    "e_l = [e+1 for e in range(num_epochs)]\n",
    "l_l = []\n",
    "a_l = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, classes) in enumerate(training_data):\n",
    "    inputs = inputs.reshape(-1,101).to(device)\n",
    "    \n",
    "    classes = classes.to(device)\n",
    "    y_hat = model(inputs)\n",
    "    \n",
    "    loss = criterion(y_hat, classes)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (i+1) % 100 == 0:\n",
    "        print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "        l_l.append(loss.item()) \n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, classes in testing_data:\n",
    "        inputs = inputs.reshape(-1, 28*28).to(device)\n",
    "        classes = classes.to(device)\n",
    "        y_hat = model(inputs)\n",
    "\n",
    "        _, predicted = torch.max(y_hat.data, 1)\n",
    "        \n",
    "        total += classes.size(0)\n",
    "        correct += (predicted == classes).sum().item() \n",
    "    acc = correct / total\n",
    "    print(f'Accuracy of the network: {(100.0 * acc):.2f} %')\n",
    "    a_l.append(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
